{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(300000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%autosave 300\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/copilot-model-run/code/Users/Soutrik.Chowdhury/unstructured_data_experiments\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\n",
    "    \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/copilot-model-run/code/Users/Soutrik.Chowdhury/unstructured_data_experiments\"\n",
    ")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "import urllib.parse\n",
    "\n",
    "import numpy as np\n",
    "from joblib import delayed, Parallel, parallel_backend\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from functools import partial\n",
    "from tenacity import retry, stop_after_attempt\n",
    "from typing import Any, Dict, List, Union\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()  # Fixing asyncio bug with Jupyter Notebook\n",
    "\n",
    "from redisvl.index import SearchIndex\n",
    "from redis import Redis\n",
    "from urllib.parse import quote\n",
    "from redisvl.query import VectorQuery\n",
    "from redisvl.query.filter import Tag\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from redisvl.index import AsyncSearchIndex\n",
    "from redis.asyncio import Redis\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFium2Loader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "import pickle\n",
    "from redisvl.utils.rerank import HFCrossEncoderReranker\n",
    "from langchain_core.vectorstores import VectorStore, VectorStoreRetriever\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_file = \"dev.env\"\n",
    "\n",
    "load_dotenv(find_dotenv(env_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAIEmbeddingFunctions:\n",
    "    \"\"\"\n",
    "    Class to get the OpenAIEmbeddings for embedding documents.\n",
    "    Attributes:\n",
    "        api_key (str): The API key of the OpenAI model.\n",
    "        api_base (str): The API base of the OpenAI model.\n",
    "        api_type (str): The API type of the OpenAI model.\n",
    "        api_version (str): The API version of the OpenAI model.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_key: str = os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "        api_base: str = os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_type: str = os.environ.get(\"OPENAI_API_TYPE\"),\n",
    "        api_version: str = os.environ.get(\"OPENAI_API_VERSION\"),\n",
    "        model_name: str = os.environ.get(\n",
    "            \"EMBEDDING_ENGINE_ADA_DEPLOYMENT_NAME\"),\n",
    "        model_deployment_name: str = os.environ.get(\n",
    "            \"EMBEDDING_ENGINE_ADA_MODEL_NAME\"),\n",
    "    ) -> None:\n",
    "        self.api_key = api_key\n",
    "        self.api_base = api_base\n",
    "        self.api_type = api_type\n",
    "        self.api_version = api_version\n",
    "        self.model_name = model_name\n",
    "        self.model_deployment_name = model_deployment_name\n",
    "\n",
    "    def get_openai_embedder(self):\n",
    "        \"\"\"\n",
    "        Get an instance of OpenAIEmbeddings for embedding documents.\n",
    "\n",
    "        Args:\n",
    "            openai_pkg: The OpenAI package.\n",
    "            model (str, optional): The model name. Defaults to None.\n",
    "            deployment (str, optional): The deployment name. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            An instance of OpenAIEmbeddings for embedding documents.\n",
    "        \"\"\"\n",
    "\n",
    "        return AzureOpenAIEmbeddings(\n",
    "            model=self.model_name,\n",
    "            azure_deployment=self.model_deployment_name,\n",
    "            api_key=self.api_key,\n",
    "            azure_endpoint=self.api_base,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_model(\n",
    "    azure_deployment,\n",
    "    model_name,\n",
    "    api_key,\n",
    "    azure_endpoint,\n",
    "    openai_api_type,\n",
    "    api_version,\n",
    "    temperature,\n",
    "    request_timeout,\n",
    "    max_retries,\n",
    "    seed,\n",
    "    top_p,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns an instance of the AzureChatOpenAI class.\n",
    "\n",
    "    Args:\n",
    "    - azure_deployment (str): Azure deployment name.\n",
    "    - model_name (str): Name of the model.\n",
    "    - api_key (str): API key.\n",
    "    - azure_endpoint (str): Azure endpoint.\n",
    "    - openai_api_type (str): OpenAI API type.\n",
    "    - api_version (str): API version.\n",
    "    - temperature (float): Temperature for sampling.\n",
    "    - request_timeout (int): Request timeout.\n",
    "    - max_retries (int): Maximum number of retries.\n",
    "    - seed (int): Seed for random number generator.\n",
    "    - top_p (float): Top-p sampling.\n",
    "\n",
    "    Returns:\n",
    "    - AzureChatOpenAI: Instance of the AzureChatOpenAI class.\n",
    "    \"\"\"\n",
    "\n",
    "    llm_model = llm = AzureChatOpenAI(\n",
    "        azure_deployment=azure_deployment,\n",
    "        model_name=model_name,\n",
    "        api_key=api_key,\n",
    "        azure_endpoint=azure_endpoint,\n",
    "        openai_api_type=openai_api_type,\n",
    "        api_version=api_version,\n",
    "        temperature=temperature,\n",
    "        request_timeout=request_timeout,\n",
    "        max_retries=max_retries,\n",
    "        seed=seed,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "\n",
    "    return llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read documents from Documents folder\n",
    "class DynamicDocumentSplitter:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        doc_folder_path: str,\n",
    "        split_type: str,\n",
    "        min_word_count: int,\n",
    "        overlap_fraction: float,\n",
    "        max_word_count: int,\n",
    "        documents: list = None,\n",
    "    ):\n",
    "\n",
    "        self.doc_folder_path = doc_folder_path\n",
    "        self.split_type = split_type\n",
    "        self.min_word_count = min_word_count\n",
    "        self.overlap_fraction = overlap_fraction\n",
    "        self.max_word_count = max_word_count\n",
    "        self.documents = documents\n",
    "\n",
    "    def get_document(self):\n",
    "        \"\"\"Get document from the file.\"\"\"\n",
    "        if self.documents:\n",
    "            return self.documents\n",
    "        docs = pickle.load(open(self.doc_folder_path, \"rb\"))\n",
    "        docs = [doc for doc in docs if isinstance(doc, Document)]\n",
    "        return docs\n",
    "\n",
    "    def get_dynamic_chunk_details(self, doc):\n",
    "        \"\"\"Determine dynamic chunk size and overlap for document splitting.\"\"\"\n",
    "        logger.debug(\"Calculating chunk details.\")\n",
    "\n",
    "        def count_func(x):\n",
    "            return len(re.findall(r\"\\w+\", x))\n",
    "\n",
    "        dynamic_chunk_sz = int(\n",
    "            np.mean([count_func(doc_element.page_content) for doc_element in doc])\n",
    "        )\n",
    "\n",
    "        if dynamic_chunk_sz < self.min_word_count:\n",
    "            return {\n",
    "                \"chunk_size\": self.min_word_count,\n",
    "                \"chunk_overlap\": int(self.min_word_count * self.overlap_fraction),\n",
    "            }\n",
    "        elif dynamic_chunk_sz > self.max_word_count:\n",
    "            return {\n",
    "                \"chunk_size\": self.max_word_count,\n",
    "                \"chunk_overlap\": int(self.max_word_count * self.overlap_fraction),\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"chunk_size\": dynamic_chunk_sz,\n",
    "                \"chunk_overlap\": int(dynamic_chunk_sz * self.overlap_fraction),\n",
    "            }\n",
    "\n",
    "    def create_chunks_docs(self, docs, chunk_details):\n",
    "        \"\"\"Create document chunks based on the specified splitting method.\"\"\"\n",
    "        logger.debug(\"Creating document chunks.\")\n",
    "\n",
    "        text_splitter = (\n",
    "            RecursiveCharacterTextSplitter\n",
    "            if self.split_type == \"recursive\"\n",
    "            else CharacterTextSplitter if self.split_type == \"character\" else None\n",
    "        )\n",
    "        if text_splitter is None:\n",
    "            raise ValueError(\"Invalid split type.\")\n",
    "\n",
    "        docs = text_splitter(\n",
    "            chunk_size=chunk_details[\"chunk_size\"],\n",
    "            chunk_overlap=chunk_details[\"chunk_overlap\"],\n",
    "            add_start_index=True,\n",
    "        ).split_documents(docs)\n",
    "\n",
    "        return docs\n",
    "\n",
    "    def get_chunked_docs(\n",
    "        self,\n",
    "    ):\n",
    "        \"\"\"Get chunks for a given file.\"\"\"\n",
    "        org_docs = self.get_document()\n",
    "        if self.split_type == \"pages\":\n",
    "            return org_docs\n",
    "\n",
    "        chunk_details = self.get_dynamic_chunk_details(org_docs)\n",
    "        chunk_docs = self.create_chunks_docs(org_docs, chunk_details)\n",
    "        return chunk_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_folder_path = \"extracted_docs/Accenture/extracted_docs.pkl\"\n",
    "split_type = \"pages\"\n",
    "min_word_count = 1000\n",
    "overlap_fraction = 0.1\n",
    "max_word_count = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_splitter = DynamicDocumentSplitter(\n",
    "    doc_folder_path, split_type, min_word_count, overlap_fraction, max_word_count\n",
    ")\n",
    "chunks_docs = doc_splitter.get_chunked_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "print(len(chunks_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args for the Vector DB Model\n",
    "added_metadata = [\"contractor_name\", \"file_version\"]\n",
    "static_metadata = [\n",
    "    \"source\",\n",
    "    \"page_number\",\n",
    "    \"file_name\",\n",
    "    \"token_size\",\n",
    "    \"timestamp\",\n",
    "]\n",
    "open_ai_embedder = OpenAIEmbeddingFunctions().get_openai_embedder()\n",
    "vector_field_name = \"embeddings\"\n",
    "embedding_field_name = \"page_content\"\n",
    "embedding_dimension = 1536\n",
    "distance_metric = \"cosine\"\n",
    "vector_algo = \"hnsw\"\n",
    "drop_index = True\n",
    "llm_re_ranking = True\n",
    "redis_host = os.environ.get(\"REDIS_HOST\")\n",
    "redis_port = os.environ.get(\"REDIS_PORT\")\n",
    "redis_database = os.environ.get(\"REDIS_DATABASE\")\n",
    "redis_password = os.environ.get(\"REDIS_PASSWORD\")\n",
    "index_name = os.environ.get(\"REDIS_INDEX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_to_hash(\n",
    "    all_docs: list, added_metadata: list, static_metadata: list\n",
    ") -> list:\n",
    "    \"\"\"Convert the documents to a hash for indexing as expected by the Vector DB model\"\"\"\n",
    "    hash_docs = [\n",
    "        {\n",
    "            \"page_content\": doc.page_content,\n",
    "        }\n",
    "        | {f\"{meta}\": str(doc.metadata[f\"{meta}\"]).lower() for meta in static_metadata}\n",
    "        | {f\"{meta}\": doc.metadata[f\"{meta}\"].lower() for meta in added_metadata}\n",
    "        for doc in all_docs\n",
    "    ]\n",
    "    return hash_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentEmbedder:\n",
    "    def __init__(self, open_ai_embedder, max_concurrent_tasks: int = 10):\n",
    "        self.open_ai_embedder = open_ai_embedder\n",
    "        self.max_concurrent_tasks = max_concurrent_tasks\n",
    "\n",
    "    async def content_embedder(\n",
    "        self,\n",
    "        content: str,\n",
    "        op_type: str = \"bytes\",\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Embed the content using the OpenAI embeddings to create embeddings for one unit.\n",
    "\n",
    "        Args:\n",
    "            content (str): The content to embed.\n",
    "            op_type (str): The operation type, either 'bytes' or the original array.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The embedding vector.\n",
    "        \"\"\"\n",
    "        embedding_vector = await self.open_ai_embedder.aembed_documents([content])\n",
    "        embd_array = np.array(embedding_vector[0]).astype(np.float32)\n",
    "\n",
    "        if op_type == \"bytes\":\n",
    "            return embd_array.tobytes()\n",
    "\n",
    "        return embd_array\n",
    "\n",
    "    @retry(stop=stop_after_attempt(5))\n",
    "    async def atomic_embedder(\n",
    "        self,\n",
    "        content_dict: dict,\n",
    "        vector_field_name: str,\n",
    "        embedding_field_name: str,\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Embed the content using the OpenAI embeddings to create embeddings for one unit.\n",
    "\n",
    "        Args:\n",
    "            content_dict (dict): The content dictionary.\n",
    "            vector_field_name (str): The name of the vector field.\n",
    "            embedding_field_name (str): The name of the embedding field in the document.\n",
    "\n",
    "        Returns:\n",
    "            dict: The updated content dictionary with the embedding.\n",
    "        \"\"\"\n",
    "        if not isinstance(content_dict, dict):\n",
    "            logger.error(f\"Content is not a dictionary, but {type(content_dict)}\")\n",
    "            raise TypeError(f\"Content is not a dictionary, but {type(content_dict)}\")\n",
    "\n",
    "        item_content = content_dict[embedding_field_name]\n",
    "        embedding_vector = await self.content_embedder(item_content)\n",
    "        content_dict[vector_field_name] = embedding_vector\n",
    "        return content_dict\n",
    "\n",
    "    async def full_embedder(\n",
    "        self,\n",
    "        content_dict: list,\n",
    "        vector_field_name: str,\n",
    "        embedding_field_name: str,\n",
    "    ) -> list:\n",
    "        \"\"\"\n",
    "        Atomic loading of each content dictionary with the embedding field.\n",
    "        This method is supposed to change as per different use cases.\n",
    "\n",
    "        Args:\n",
    "            content_dict (list): The list of content dictionaries.\n",
    "            vector_field_name (str): The name of the vector field.\n",
    "            embedding_field_name (str): The name of the embedding field in the document.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of content dictionaries with the embedding field updated.\n",
    "        \"\"\"\n",
    "        if isinstance(content_dict, dict) or isinstance(content_dict, list):\n",
    "            semaphore = asyncio.Semaphore(self.max_concurrent_tasks)\n",
    "\n",
    "            async def sem_task(content):\n",
    "                async with semaphore:\n",
    "                    return await self.atomic_embedder(\n",
    "                        content, vector_field_name, embedding_field_name\n",
    "                    )\n",
    "\n",
    "            tasks = [sem_task(content) for content in content_dict]\n",
    "            results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "        else:\n",
    "            logger.error(\n",
    "                f\"Content is not a dictionary or list, but {type(content_dict)}\"\n",
    "            )\n",
    "            raise TypeError(\n",
    "                f\"Content is not a dictionary or list, but {type(content_dict)}\"\n",
    "            )\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The object to embed the documents\n",
    "hash_docs = document_to_hash(chunks_docs, added_metadata, static_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embedder = DocumentEmbedder(open_ai_embedder, max_concurrent_tasks=10)\n",
    "embedded_hash_docs = await doc_embedder.full_embedder(\n",
    "    hash_docs,\n",
    "    vector_field_name,\n",
    "    embedding_field_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "print(len(embedded_hash_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_content': '(ii) For countries with inflation above 15% per year, any invoice remaining unpaid for more than thirty (30) days from payment date shall be increased by the interest defined in paragraph (a) above plus an amount of money based on the COLA index for the respective country, calculated for the period between the invoice due date and the effective payment date.\\n\\n(d) If Customer does not submit the PO number within ten (10) Business Days following the date on which the invoice should have been submitted, Supplier will have the ability to submit the invoice without the PO number. In case of Supplier not receiving the PO within ten (10) Business Days or of Customer rejection of the invoices solely as a result of the absence of a PO number, Supplier is entitled to:\\n\\n(i) not start the relevant Service or suspend the relevant Services without any penalty, until the PO is provided or the invoice is accepted by Customer; or\\n\\n(ii) apply late payment interest in accordance with paragraph (c) above in the event that the invoice is not paid within the payment terms set out in paragraph (a) as a result of the failure to issue the PO late.\\n\\n6.4 Payment means\\n\\nPayment may be made electronically to an account specified by Supplier or by other means set out in the SOW or otherwise agreed to by its Parties.\\n\\n6.5 Payment disputes\\n\\nIn the event of a good faith dispute between Customer and Supplier as to the Fees and/or expenses shown on an invoice, Customer shall provide written notice to Supplier detailing its grounds for dispute within thirty (30) days of receiving the applicable invoice. Customer may then suspend payment of the Fees and/or expenses shown on the invoice to Supplier. The Parties each agree to resolve any such dispute within thirty (30) days of Supplier receiving Customer\\'s written notice (“Resolution Period”) and Supplier agrees to continue to perform its obligations under this Agreement and every applicable SOW in good faith during the Resolution Period. Upon dispute resolution, Customer and Supplier shall allocate the disputed amount according to the agreed resolution of the dispute. For the avoidance of doubt, Customer shall pay any Fees and/or expenses (or portion thereof) which are not the subject of a dispute under this Clause 6.6 (Payment disputes), in accordance with Clause 6.3 (Payment Terms).\\n\\n6.6 Foreign Exchange\\n\\nThe Fees and the currency of invoices for the Services provided will be in local currency, i.e. the currencies of the locations where the services are received. Locations and currencies will be specified within the SOWs. The amount of the Fees may be stated by Supplier in the local currency of the locations where the services are delivered. The mechanism for converting any Fees stated in the currency of the location where the services are delivered, to the currency of the locations where the services are received, will be set out in the relevant SOW.\\n\\n6.7 COLA – Cost of Living Adjustments\\n\\n(a) In relation to \"FIXED FEE\" arrangements, COLA application will be defined in the SOW following the principles in Schedule 1 of this Agreement. Any adjustment will be applied on each anniversary of the Effective Date of the SOW in respect of COLA in that location during the year expiring immediately before that date.',\n",
       " 'source': 'accenture__original__msa completely signed accenture',\n",
       " 'page_number': '18',\n",
       " 'file_name': 'msa completely signed accenture',\n",
       " 'token_size': '653',\n",
       " 'timestamp': '2024-08-19 09:43:55.050748',\n",
       " 'contractor_name': 'accenture',\n",
       " 'file_version': 'original',\n",
       " 'embeddings': b'\\xc9\\xb9\\xb4\\xbbiX\\x1b;\\xe5P$\\xbc~5y\\xbc\\xae\\xbbW\\xbc)\\x15\\xf3\\xbb\\x16\\xd1\\'\\xbd\\xb0Tj\\xbb\\xdeG\\x11\\xbc{\\xa8\\x9c\\xbc\\x7fW\\xd4<\\xcct\\xa2<\\x88\\x82\\xc2\\xbb\\x15,\\xdf<\\xfc\\xcc\\xef;#P\\x16\\xbc\\x0e\\xa0^<\\xdad\\xed;\\x7f\\xda\\xc1;Q\\x92\\xbe;\\'|\\xe0\\xbc\\x8f\\xec\\xe7<\\x88\\x050\\xbd}\\xc4\\x9c<\\xa7W\\x8d\\xbc|\\xa2A\\xbc\\xf6\\\\\\xef<@<\\xe2\\xbc\\x12\\xfa9<K\"><\\x12\\xfa\\xb9;\\xfd\\xeeJ\\xbcY\\x1e\\xbf\\xbcN\\xb5\\xf5\\xbb\\xeeS\\xdc\\xbc\\x0eK\\x02\\xbc\\xf0\\xec\\xee9\\x834\\x1d\\xbcZ\\xc3\\x87\\xbaU\\xc4\\xe3\\xbb\\xa9E\\xfc<J\\x89+<\\xb3\\xb4 \\xbaQ\\x98\\x19;\\x10a\\xa7\\xbaO|\\x19:\\xcc\\xf14\\xbb\\xf16\\x00\\xbc\\x9aU1<\\x17\\xc5\\xf1<\\x17\\xcb\\xcc<\\x00\\'\\xcb<\\x93\\xc3U\\xbc\\xea|n\\xbc\\x8b=0\\xbb\\xc0\\x94\\xa1;\\x9a\\xd8\\x9e\\xbc\\xaf\\xe3\\x8d<\\x06\\x1a9\\xbc/\\x8bN\\xbc(\\xa4\\x16;\\x16N:<\\xe2\\x9b\\x11\\xbcPv\\xbe<\\x84\\xd3\\n\\xbd\\xc4e\\xb4\\xbc\\x0b\\r\\xa7\\xbc>\\xcb\\x85<^\\xef\\xd1\\xbb\\xa1<\\xe9;\\x1d\\xb8\\xdf<\\x1b%(=\\x92\\xc9\\xb0<E\\xb2\\xbd\\xbb\\x7f\\xda\\xc1<\\xcf)\\xb5\\xbc\\xf3L\\xa5\\xba\\xaf\\xe3\\x8d;C\\x9c\\x98\\xb9\\xaa\\xe4i<\\x8a\\x15z<LD\\x99\\xbc)\\x1bN;W\\x85\\xac;\\x1a+\\x83<\\x8dSU\\xbai\\xd5-<\\xb5%\\xfd;E\\r\\xf5\\xbc\\x02=p<\\xce\\x84l<x\\xc5x<\\xa0H\\x9f;\\x14\\xbb\\x02=P\\xf3P;H\\xea\\xbd<v\\xb5\\xae\\xbc\\xa1<\\xe9<h\\xb9\\xad;6\\x1d*\\xbd/\\x85\\xf3\\xbb<\\x87O<i\\xdb\\x08\\xbd\\xb5\\xd0 \\xbc\\x9c\\x93\\x0c\\xbd\\\\\\xd3\\xd19\\x82\\x8fT<`-\\xad\\xbc\\xdeG\\x91<\\xdadm\\xbb\\x86f\\xc2\\xbc\\x0e\\xa0\\xde<\\xd6\\xbb\\x10=E\\xb8\\x98;\\x12\\x9f\\x02<\\xac}|\\xbc6\\xa0\\x97;\\xad\\x1cj\\xbcGQ+\\xbc\\xb5\\xd0\\xa0\\xbc\\x9d\\x8d1<[\\\\\\x1a<\\xe7\\xe9\\xb6<`-\\xad\\xbb6\\x1d\\xaa;\\x8eu0\\xbcfuw\\xbc\\x07<\\x14\\xbc\\x82\\x0cg:}G\\x8a\\xbc\\xde\\xc4\\xa3\\xbc\\x11}\\xa7<\\x00O\\x01<wT\\x1c\\xbb\\xf9\\xbc\\xa5\\xbb\\xf6\\x8a\\x00;\\xfd\\x16\\x01\\xbd\\xc1\\xb0\\xa1\\xbb\\x8b7\\xd5\\xbc\\xaa\\xe4\\xe9\\xbcR\\x8c\\xe3;\\xfe\\n\\xcb<\\xa9s\\x8d\\xbc\\xfa\\xde\\x00\\xbcc=w<D\\x13\\xd0<\\xb3\\xb4 =m\\x8a\\xc0\\xbc\\x9b\\xf4\\x1e\\xbb\\xb2\\x15\\xb3\\xbb\\x1d\\xe0\\x95<\\x96~C\\xbb\\x82\\x0cg;\\x0f\\xbc^\\xbc\\x81\\x18\\x1d;Z:\\xbf;q\\xe4\\x9b<\\x16\\xd1\\'=\\xe3\\x0c\\xee<:\\xcc\\xe1\\xbc\\xa9\\xf0\\x9f:\\xd7,\\xed:\\xaa\\x0c ;\\x03\\x87\\x01<`\\xb0\\x9a\\xbc\\x15\\xd7\\x82<\\xbc:F\\xbc+_\\x84\\xbc\\xcaX\"\\xbcVi\\xac;5~<;\\x12\\x9f\\x02=o\\x1dx;@<\\xe2<\\xd9\\xcbZ<p\\xbc\\xe5<*\\xba\\xbb\\xbb\"\\xb7\\x83\\xbc\\xad\\xc7\\r\\xbd\\xac}\\xfc\\xbco\\x1d\\xf8\\xba\\xdc\\xa8\\xa3<\\xe1y6\\xb8\\x7f\\xda\\xc1<\\xefu7\\xbc\\x05\\xa3\\x81\\xbbD;\\x86<\\xbex\\xa1\\xbbw\\xd7\\t;\\x12w\\xcc\\xbbv\\xb5.;:w\\x05<\\x11}\\':\\x00O\\x01\\xbc\\xc4\\xe8!\\xbf\\xd1\\xbc\\xec\\xbc\\xdc+\\x11\\xbb79\\xaa\\xbc\\xb6\\xc4\\xea\\xbb\\x8a\\x15z;\\xec=\\xb7<\\xe1\\x7f\\x11\\xbaS\\xae\\xbe\\xbc\\xaf\\xdd\\xb2<\\x18\\xed\\'\\xbc\\x8dSU<\\xf1\\xb3\\x12\\xbcm\\x07S<\\xe1\\xf6\\xc8<\\x84\\xd3\\x8a\\xbc\\xb0Tj\\xba\\x9aU\\xb1\\xbc\\xd3\\x83\\x90\\xbc\\x07<\\x14;@\\xe1\\xaa;\\xd7,m<\\xfc\\xfa\\x80;o\\x1d\\xf8<wT\\x9c<\\xec\\xba\\xc9\\xbc\\xaf\\xb5\\xfc\\xba\\xe2\\x9b\\x91\\xbc\\x01\\xc6\\xb8\\xbc\\x11\\xd8^;\\xcb\\xf7\\x0f\\xbc\\x08X\\x94<\\x19\\x8c\\x95\\xbb\\x89\\'\\x8b<\\xcaX\"=\\x85D\\xe7;\\xd1?\\xda\\xbcwNA\\xbcf \\x1b<\\xdajH=a\\xa4\\xe4\\xbc\\x1d\\xe0\\x15\\xbb\\xa6\\r|\\xbc\\x14\\xbb\\x02\\xbd\\x18\\xed\\'\\xbb\\xd4}5<\\xad\\x9fW<\\xff\\x04\\xf0\\xbb\\x1c\\xbe:\\xbbHE\\xf59\\x00\\xa4\\xdd;\\x18\\xe7\\xcc:4\\\\\\xe1\\xbb(\\xa4\\x96\\xbc&\\x0b\\x04<\\xa4\\xf7\\xd6;\\xa3\\xd5\\xfb\\xbb\\x12\\xf4\\xde\\xba*\\xb4`\\xbc\\xd9\\xcbZ<\\x04\\xfe8<aO\\x08\\xbc\\xf7#\\x93\\xbc\\x1f\\x7f\\x03\\xbd\\xc7u\\xfe\\xbc\\xa3\\x03\\r<\\x97\\x9a\\xc3\\xbc\"\\xb7\\x83<\\xcf)\\xb5<(\\'\\x04=>\\x9dt\\xbb=\\xa9\\xaa<t\\x9f\\x89\\xbb\\xdb\\x86H\\xbdB\\xfd\\xaa\\xbb\\xfcw\\x13<1$a<\\x92L\\x1e<\\xf2\\xad\\xb7\\xba\\x15,_<?\\xbf\\xcf\\xbc\\x12\\xfa\\xb9\\xb8\\x9e,\\x9f;>\\xcb\\x05\\xbd\\xc9\\xb3Y<\\xc96G;:\\xcca;79*\\xbbX\\x7f\\xd1\\xba\\x14\\x10\\xdf\\xbb\\x8a\\xc0\\x9d\\xbc\\xc1\\x05~:/\\x0e\\xbc<\\xfbO]\\xbc2\\xbds\\xbb\\x08X\\x94<j\\xf7\\x08<F\\xac\\xe2\\xbc\\x0f\\xbc\\xde:\\xad\\x1c\\xea\\xbcm\\x84e\\xbcX\\xa7\\x87\\xbc\\x8c\\xb4g\\xbbck\\x88<\\xd4\\xf4\\xec<\\xa0\\xc51<\\x0c\\x84^\\xbc\\x7f]\\xaf\\xbb\\xef\\xf8$=\\x0c\\x8a9\\xbd\\x02\\xe8\\x93<\\x96#\\x8c\\xbc=\\xaf\\x85\\xbb\\n\\xebK\\xbc\\x9aOV\\xbce\\x04\\x9b\\xbc\\xb1\\xf3W<\\xc5_\\xd9\\xbb\\xf3$\\xef;\\xba\\x1e\\xc6\\xbar\\x83\\t<\\xc2\\'Y<`\\x05\\xf7<\\xe8\\x0b\\x12\\xbc=\\xaf\\x85\\xbcm\\x84\\xe5<\\xb1\\xf9\\xb2\\xbb\\x7f]/\\xbb\\x85\\xc7T;D\\x96=\\xbc\\x80\\x7f\\n\\xba\\x0e\\x1dq\\xbcu\\x93\\xd3<\\xdad\\xed\\xbc\\x8f\\x97\\x0b=f \\x9b\\xbc(!\\xa9<h\\xb9-<(\\x9e;<\\x87\\x0b\\x0b\\xbdM\\xc1\\xab\\xbc)\\x15\\xf3:OT\\xe3<\\x04{\\xcb\\xbc\\x0e\\x1dq;\\xf0\\x97\\x12\\xbd\\x19\\x86:\\xbb\\xc5\\xdc\\xeb;C\\x19+\\xbb\\xa9s\\x8d<F/P\\xbcz\\t\\xaf\\xbc\\x19\\x86\\xba:\\xea!\\xb7\\xbc>\\xcb\\x05\\xbcX\\x7f\\xd1;\\x1a\\x80_\\xbc\\xb4\\xae\\xc5\\xbbw\\xd1.\\xbd\\x87\\xddy\\xbcg\\x1a@\\xbc\\x0bh\\xde:3b<\\xbai\\xadw\\xba\\xc7 \"\\xbc&\\x0b\\x84\\xbc\\xa3z\\xc4<\\xf8\\x1d\\xb8<\\x0e\\xc8\\x94\\xbc\\xa6;\\r\\xbd\\xaf\\xb5|<n\\xac\\x1b\\xba\\xc1\\xb0!<\\xec7\\xdc<Q\\xedu\\xbc\\x91*\\xc3;\\xb413\\xbc\\xe4.\\xc9<Bz\\xbd\\xbc[\\xdf\\x87\\xbc&\\x0b\\x04<\\x1a\\xa8\\x15\\xbb\\x0e\\xa0\\xde:\\xcf\\xac\\xa2\\xbc\\x00O\\x01=\\xc9\\xb9\\xb4;\\x06\\xbf\\x81:UG\\xd1<\\x0b\\x13\\x02:\\xf4\\xc3\\\\<\\t\\xf7\\x81\\xbb\\x0fg\\x82;8[\\x85<\\x148\\x95<E\\xb2\\xbd\\xbc\\xd3\\x83\\x90;F/P\\xbc\\x19\\x0f\\x83\\xbc5#\\x05=\\xbc\\xb7\\xd8<\\xf20%=N\\xe3\\x86;\\x05u\\xf0<\\xf5\\xe5\\xb7<\\x1f\\xfc\\x95\\xba\\x84\\xabT\\xbb\\xe2\\x18\\xa4;o\\xc8\\x1b\\xbd\\xab\\x83W=|\\xa2A=\\xf6\\x07\\x93;|\\x9c\\xe6\\xbc\\x92\\xcf\\x8b\\xbcA\\x03\\x86\\xbc\\x0e\\x1dq<O\\xff\\x06\\xbbVc\\xd1\\xbb\\x93\\xc3U\\xbc\\x9e\\xa9\\xb1<\\xa1\\xe1\\xb1<\\xb41\\xb3;Q\\x92>\\xbc.\\x14\\x17=f\\x9d\\xad\\xbb\\xd4}\\xb5\\xbb\\x9e,\\x1f\\xbc\\x0e\\x1dq;\\x80\\xf6\\xc1<\\xbc:\\xc6;\\xd7,m\\xbcCt\\xe2\\xbb\\xc7 \\xa2\\xbc.\\x91\\xa9<X\\xfc\\xe3<Z@\\x1a;\"\\xb7\\x03<\\xb5\\xca\\xc5<\\xff\\x04p\\xbcr\\x83\\t=\\x93\\xeb\\x0b\\xbc\\x96\\xf5z\\xbb@\\xe7\\x05=\\x12\\xfa\\xb9<\\x8c\\xb4g\\xbc<\\x8d*\\xbb\\xbb\\x95}:\\x8f\\xecg<\\xd7\\xb5\\xb5<\\x01\\xcc\\x13\\xbc\\x14\\x8dq<<\\x87O\\xbb\\xf3L%\\xbag\\x97\\xd2\\xbc\\xc5\\x87\\x8f\\xbcrUx\\xbc\\xf0\\x1a\\x00\\xbc_\\x8e\\xbf<\\xb6GX<@\\xe1\\xaa<TM,<\\x02=p<s\\xfa@\\xbcjLe<m\\x84\\xe5;\\xfe\\x10&<\\x993V<\\xfa\\xb6J;5\\xf5s\\xbbv,f\\xbbQ\\x1b\\x87\\xbc\\x95\\\\h\\xbc\\xdd\\x1f\\xdb\\xbc%f\\xbb\\xba{+\\x8a\\xbc\\xbe\\xcd}<$\\xc7M<\\xc5\\x87\\x8f<\\x1b\\x1fM\\xbc\\xa3\\xfd1<!\\x0c\\xe0<Y\\x9b\\xd1\\xbc\\xf8\\xa0%\\xbc\\x8f\\x14\\x1e<[\\xdf\\x07=\\x18\\xe7\\xcc\\xbb3\\xdfN<\\x1f\\xfc\\x95:\\x02=\\xf0\\xbb\\x0eK\\x02;yd\\xe6;\\x03\\x87\\x01\\xbdR7\\x87<\\xdc+\\x91\\xbb\\xb5S\\x0e\\xbc`\\x05w<`\\x05\\xf7;\\xd9\\xc5\\x7f;\\xff\\xaf\\x93\\xbc\\xad\\xc7\\r\\xbc\\xa3\\x80\\x1f\\xbc~c\\x8a\\xbbx\\xf3\\x89\\xbc|\\x9c\\xe6\\xbb\\xf0\\xec\\xee;\\tR9=Hs\\x869\\x17p\\x15\\xbcK\"\\xbe\\xbc\\xb8\\x853\\xbc\\xaf\\xb5\\xfc\\xbb\\x16N:<\\x11\\x00\\x15\\xbdr}\\xae\\xbc\\x0e\\xa0\\xde<1L\\x17=:\\xf4\\x17<Y\\xa1,<\\x9f\\xa3\\xd6\\xbc\\x98\\x94\\xe8<Ig\\xd0\\xba\\xdc\\xfd\\x7f<\\xd1\\xbc\\xec\\xbb\\xf3$o\\xbb\\xfd\\x16\\x01\\xbbZ\\xc3\\x87=\\xd5\\x1c\\xa3< \\xf0\\xdf;\\xf5\\xdf\\xdc<\\xdeG\\x11\\xbcN`\\x19<\\xec=\\xb7\\xbc\\xf6\\x07\\x93\\xbc\\xb8\\x02\\xc6<\\xbf\\xefX\\xbb\\x8eu\\xb0\\xbbY\\x1e\\xbf\\xbb\\xd5\\x1c\\xa3<\\x96#\\x8c\\xba&\\x0b\\x04=\\xd0\\x1d\\x7f<\\xbb\\xbd\\xb3<4\\\\\\xe1\\xbc4\\x07\\x05=\\x92$h<L\\x9f\\xd0;\\x02e\\xa6\\xbbydf<$D`=\\x0f?\\xcc;\\x11\\xd8\\xde\\xbb\\x94\\xdfU=K\"\\xbe<\\xcd\\x90\\xa2<\\x0b\\xe5p\\xbc\\x1a+\\x83\\xbb\\xd7\\xaf\\xda\\xba8-\\xf4:\\xd2g\\x90\\xbb[\\xb7\\xd1<\\x17\\xf3\\x02=\\xb7cX<\\xf3\\xc9\\xb7\\xbc\\xb8]}; \\x18\\x16\\xbc\\xcf#Z;\\xdb\\x8c\\xa3<\\xa1\\xe11\\xbcE\\xb8\\x98\\xbb\\x8a\\x1bU:\\x0b\\xe5\\xf0\\xbc\\x9ckV\\xbbU\\xec\\x99<\\x0e\\xc8\\x94\\xbb-oN<,M\\xf3<\\xd2\\xde\\xc7\\xbb<\\x8d*;g\\xbf\\x08\\xbb{+\\n=\\x11U\\xf1;#\\xd3\\x83\\xbc\\x1dc\\x03<\\x8dMz<HE\\xf5\\xbc\\x99\\xb6C\\xbd\\xe9\\xff\\xdb\\xbc\\xdad\\xed<\\xf8\\x1d8\\xbc\\x90\\xb3\\x0b\\xbc\\x05 \\x94\\xbc\\x85JB:3b<<m\\x07S\\xbce{\\xd2<\\xe6\\xc7\\xdb\\xbb\\xff,\\xa6\\xbc\\x93FC\\xbb\\'\\xffM<q[\\xd3<\\xe5\\xd3\\x91\\xbc\\xb1vE\\xbbW\\x8b\\x87<\\xdeG\\x91\\xbc\\x12w\\xcc;\\xdc\\xfd\\x7f;\\x9e\\xaf\\x8c\\xbcg\\x14e\\xbc7?\\x05\\xbcck\\x08\\xbc\\xf2\\xa7\\xdc<\\xb7\\xe6E\\xbc?B\\xbd<\\xd68\\xa3\\xbc\\xac\\xab\\r;\\t\\xf7\\x01\\xbc\\xab\\x83W\\xbbh<\\x1b\\xbc\\xec\\xc0\\xa4;\\xbfr\\xc6<r\\x83\\t<\\xa6;\\r<\\xa3z\\xc4;\\xb5\\xd0 <\\xcf#Z;\\x89\\xa4\\x9d\\xbb\\xfbO\\xdd\\xbc\\x85J\\xc2\\xbb\\x8dSU\\xbb\\x8f\\xec\\xe7;\\xc7\\xa3\\x8f<\\xdc+\\x11\\xbb\\xa4ti\\xbb?\\xbfO\\xbc{\\xfdx\\xbc\\xc5\\x87\\x0f;8-\\xf4\\xbc\\x17\\xcb\\xcc<\\x08X\\x94;\\xd3U\\xff\\xbc\\xe9\\x05\\xb7<\\xff,\\xa6\\xbb\\x96~C;\\xcd\\r5=\\xa3\\xd5{<\\x88\\x82B:4\\x07\\x85\\xbc\\xc7u\\xfe;\\xe5\\xd3\\x91<\\xd1E\\xb5\\xba\\x88|g;\\x9e\\xa9\\xb1:\\x92\\xc9\\xb0\\xbb=\\xaf\\x85\\xbb!\\x8f\\xcd\\xbc\\x1a\\xa8\\x15<\\xd6\\x93Z\\xbb=,\\x18\\xbc\\xe2\\x18$\\xbcE\\ru\\xbc@\\xe7\\x85\\xbb\\xdd\\x9cm\\xbcVi\\xac\\xbb\\x8d\\xd6B\\xbd\\xfcw\\x93;Bz\\xbd\\xb95#\\x05\\xbc7\\xbc\\x97:\\xebC\\x92\\xbc\\x9d\\x8d1=\\xf4F\\xca\\xbc\\x06\\x14^:\\xd1\\xbcl\\xbcL\\x1c\\xe39(\\'\\x84<\\xb0Tj<\\x1e\\xda\\xba;\\x1b\\x1fM\\xbb\\xca\\xd5\\xb4:\\x9d\\x8d\\xb1;\\xfc\\xfa\\x80\\xbcR\\xb4\\x99\\xbbB\\xf7O\\xbd\\xeeS\\xdc<J\\x06\\xbe<m\\x07\\xd3<\\xbb\\xc3\\x8e\\xbbh\\xb9\\xad<Z\\xc3\\x07<VcQ\\xbc\\xf3\\xc9\\xb7;\\xc1-\\xb4\\xbc&\\xddr\\xbb\\x8c_\\x8b\\xbcZ\\xc3\\x07<i\\xadw<\\x0fg\\x82<\\xaf\\xdd\\xb2\\xbb\\x88\\xff\\xd4\\xbc83O<s\\xfa\\xc0;Z\\x95v\\xbc\\x98\\x94h:W]v\\xbc\\xc5\\xdck\\xbc\\x88|g\\xbc\\xfd\\x16\\x01;\\x98?\\x0c<f\\x9d\\xad<\\xd9\\xcb\\xda\\xbc\\xb8\\x8b\\x0e\\xbc>\\xcb\\x85<O\\xff\\x06\\xba\\x95\\x07\\x8c<\\xba\\xa13\\xbaV\\xe6\\xbe<*\\xb4\\xe0\\xbbW\\x85,=%\\xe9(9\\x7f\\xd4\\xe6;1$\\xe19\\xa1d\\x9f\\xbc\\xd8\\xd1\\xb5\\xbc\\xa3zD<\\xf1\\x0eJ\\xbb\\x16N:\\xbc1\\xc9\\xa9<\\x80\\xfc\\x1c\\xbc\\xac\\xab\\x8d\\xba\\xed_\\x12\\xbd\\x8cY\\xb0\\xbb\\xe1\\xfc#\\xbc\\xc3C\\xd9\\xbc\\xe5P$\\xbc\\x9e,\\x1f\\xbc\\x98\\xbc\\x1e:\\x17\\xc5\\xf1\\xbc\\x00O\\x81<Z\\x95\\xf6:y\\xe7\\xd3\\xb9\\x80y\\xaf<\\x97\\x9aC<\\x88\\x05\\xb0<\\xeeS\\xdc\\xbb5#\\x05\\xbd\\xc2\\xa4\\xeb<\\x08X\\x94\\xbc\\xe6D\\xee<\\xa5\\x13\\xd7\\xbc\\x17\\xc5\\xf1<\\x06\\xbf\\x01\\xbbF\\xd4\\x18\\xbb\\xce\\x84\\xec\\xbc\\xe0W[\\xbc\\xd5\\x995\\xbc\\x19\\x0f\\x03<;et<\\xfa\\xde\\x00=\\xfd\\x16\\x81\\xbc\\xa5\\x96\\xc4\\xbc\\x90\\x0eC;\\x06\\x1a9\\xbb\\xdf\\xe0\\xa3\\xbb\\xf5b\\xca\\xbcS\\xae>=4\\\\a:\\xa4ti<\\x1f\\xfc\\x95\\xbc\\x17p\\x95\\xbb\\xc1\\xb0\\xa1\\xbb|\\xa2A<\\xf5h%\\xba%l\\x16<~c\\x8a\\xbb+\\xdc\\x96\\xbbck\\x88<\\xe4\\xb16<\\xc2\\'\\xd9\\xbbz\\t/<n\\xac\\x9b<]\\xcd\\xf6\\xbc\\x08\\xd5\\xa6\\xbc\\xfc\\xf4\\xa5\\xbb4\\\\\\xe1\\xbb\\x03\\xdc\\xdd;P\\xf3\\xd0\\xbbq\\xde\\xc0<1\\xc9)\\xbc+_\\x84<\\xb0\\xd7W\\xbcQ\\x1b\\x87<`\\x05w\\xbc\\xdd\\xa2\\xc8\\xbcbC\\xd2<\\xbflk<\\x95\\x011;\\xa3\\x03\\x8d\\xbb\\xab\\x83\\xd7<\\x93\\xbdz\\xbb\\xc6\\x814\\xbcTS\\x07\\xbcQ\\x1b\\x87\\xbcn).\\xbb\\x12w\\xcc\\xbb@<b\\xbc\\xdc\\x03\\xdb;\\x17\\xf3\\x02=\\xc6\\x04\"\\xbdZ\\xc3\\x87<F\\xac\\xe2;\\xcct\\xa2\\xbb\\xac\\xab\\x8d;f\\xa3\\x88<\\x1b\\xa2\\xba;\\xc1-\\xb4<\\xc5\\x87\\x0f\\xbc!\\x0c`<\\x92L\\x1e\\xbb\\x08\\xadp<\\xe8\\xe3\\xdb;_\\x94\\x9a<\\xb8\\x8b\\x0e\\xbc)C\\x84<;\\x93\\x85\\xbc\\xf0\\x1a\\x00=\\x0b\\x90\\x94\\xba$J;:qa\\xae\\xbc,S\\xce<\\xd9p#\\xbdrU\\xf8\\xbcf\\xa3\\x08=\\x93\\xbdz\\xbc\\x80\\x7f\\n\\xbd\\x85\\xcd\\xaf:\\'\\x05)\\xbbu\\xbb\\t<\\xb1v\\xc5\\xbc\\xfbO]<4\\x84\\x97<7?\\x85<e\\x04\\x1b:\\xb6\\xc4j\\xbc\\x83.B\\xbbVcQ\\xbb)\\xc0\\x16<\\x00O\\x81\\xbb\\xd72\\xc8<\\x84\\xa5y\\xbc~\\xe0\\x1c<>\\xa3\\xcf<i\\xdb\\x88<\\xec\\xc0\\xa4\\xbcU\\xc4\\xe3\\xbc\\xbb\\x95}\\xbch\\xb9-<\\xd6\\x8d\\x7f<\\x91\\xad0;\\x98\\x94h\\xbc\\x03\\xe2\\xb8\\xbb:w\\x85\\xbcM>>\\xbc\\xbf\\xef\\xd8<5~\\xbc\\xbc\\xb1\\xf3\\xd7\\xbb}G\\n9\\x9f\\x9d\\xfb<.\\x97\\x04=\\x19\\t\\xa89u\\x8dx\\xbb\\x13\\x99\\xa7\\xbbW\\x08\\x9a\\xbc\\x91*C\\xbc\\xd0\\x1d\\xff\\xbc3h\\x97\\xbc\\xbc\\xb7X\\xbcX\\x7fQ<K(\\x19=T%\\xf6\\xbc\"\\xb1(\\xbcm\\x8a\\xc0\\xbc\\x11\\x83\\x82\\xbc\\xa1<i\\xbb\\xe5P$\\xbd\\x9a\\xd8\\x9e< sM<\\xdd\\xa2H<\\xdc\\xa8#<\\x16N\\xba<kn@\\xbb\\xc8\\x14\\xec<\\xba\\xa1\\xb3\\xbc\\x86\\xe9/;\\xa6\\xb8\\x9f;ydf\\xbc\\x88|g\\xba\\x0b\\x13\\x02<#P\\x16\\xbd\\xb5\\xd0 ;\\t\\xf7\\x01=\\xc2\\xa4\\xeb;n\\xac\\x9b<\\xaa\\x0c\\xa0;\\x9d\\x8d\\xb1:X\\xfc\\xe3\\xbc\\x93\\xeb\\x0b<\\x1f\\xf6:<\\xa4\\xf7V\\xbcI\\x8f\\x86;\\xd4\\xf4l<rUx\\xbc\\x86fB<[4d\\xbc\\x1c\\xc4\\x15;v,f\\xbd\\xd2g\\x90<\\x0eE\\'\\xbc\\xb7\\xe6\\xc5\\xbc\\xb0| 8M>\\xbe\\xbbg\\x1a@\\xbc\\x8eoU\\xbc\\xcd\\xe5~\\xbc\\xd9\\xc5\\xff<oK\\t<\\x95\\\\\\xe8;\\x19\\x8c\\x15<\\xd5\\x1c\\xa3;C\\x19\\xab\\xbc\\xff\\x04\\xf0\\xbc\\xfd\\xeeJ:Q\\x15,\\xbc\\xed\\xb4n\\xbc\\x1cG\\x03=\\x02e&;\\xdajH<\\xea|\\xee\\xbb]\\xf5,\\xbaW\\x8b\\x87\\xbc\\xe7\\xe969\\xaf\\xb5\\xfc\\xbb\\xfa\\xb6J;\\xce\\x07Z\\xbc\\xd8NH<0*<:>\\xcb\\x05\\xbd\\xd0\\xc8\\xa2;\\\\\\xd9\\xac\\xbc\\xb5M\\xb3<\\x1d;\\xcd\\xbc79\\xaa\\xbc\\x14\\xbb\\x02\\xbd\\xdc\\xfd\\x7f;\\xc7 \\xa2\\xbc00\\x97\\xbc\\x9bq1\\xbc\\xdfc\\x11\\xbb;e\\xf4\\xbbA\\xd5\\xf4\\xbb\\xf8\\x9a\\xca\\xbc\\xd1\\xbc\\xec;\\'|`>U\\xec\\x19<\\xe5\\xd3\\x11\\xb9\\xa6\\r\\xfc<\\xb9\\xfcj\\xbc\\xdd\\x1f[<IgP<A\\xd5\\xf4\\xbb\\xcf)5\\xbc\\x87\\xddy<OT\\xe3\\xbc\\x07\\xb9\\xa6<\\xfcw\\x93\\xbc\\x7fWT<\\xdf;[\\xbb\\x12\\xf4\\xde\\xbb\\x1b%(\\xbd\\x11\\xd8\\xde\\xbcu\\xbb\\x89\\xbc\\xc2O\\x0f=\\xa1<\\xe9;W\\x8b\\x07=\\xae>E\\xbc#\\xa5\\xf2\\xbb\\xeeS\\\\\\xbbZ\\x95v\\xbc\\xa0\\xbfV;\\xa5\\x96D:\\xc2\\xaaF<\\xbd\\xd3\\xd8<\\x90\\xb3\\x0b\\xbc\\x04\\xfe8;\\x152:<\\xdd%6\\xbc\\xb7cX\\xbc?H\\x98<\\x0c\\x84^;\\xce\\x8aG\\xbct\\x16\\xc1<\\t\\xf7\\x01<\\x9c\\x93\\x8c<\\xc6\\x04\\xa2\\xbb\\x88\\x050\\xba\\x89\\x9e\\xc2\\xbc\\xb9\\xfcj\\xbb\\xff,&=\\x8a\\xc0\\x1d<w\\xd7\\t\\xbc\\x92$\\xe8\\xbc\\xdb\\x8c#<\\xcb\\xcfY\\xbd\\xc3CY\\xbc7?\\x05=w\\xd7\\t=\\x8f\\x97\\x8b<\\nt\\x14;\\xa9\\xf0\\x9f;\\xce/\\x10=i\\xd5\\xad\\xbc.\\x91)<\\xfd\\xeeJ\\xbc\\x8e\\xf2\\xc2;\\x88|\\xe7\\xba\\xc4k\\x8f\\xbb9\\xd8\\x17\\xbc3h\\x97<\\x1b\\x1f\\xcd\\xbb]x\\x9a\\xbc\\x90\\x85\\xfa\\xbb\\xf0\\x97\\x12\\xbd\\tL^;6\\x1d*\\xbc\\x87\\x88\\x1d<\\xcb\\xf7\\x8f:e\\x81\\xad\\xbc\\xd4\\xf4\\xec\\xbb`\\x05w\\xbbG\\xce\\xbd<1$a\\xbbB\\xfd*=3b<\\xbb\\xa1\\xe7\\x8c\\xbc\\x00\\xa4\\xdd\\xbc]\\xcd\\xf6;\\xb7i3\\xbcu\\xbb\\x89\\xbcI\\x8f\\x06<\\xcd\\x90\"<\\x9b\\xcc\\xe8\\xbc\\x86l\\x9d\\xbcrU\\xf89\\xd6\\x8d\\x7f\\xbc\\x1e\\xda\\xba\\xbcB\\x80\\x98<\\xbd\\\\\\xa1\\xbc\\xe9\\xff\\xdb:\\x8dM\\xfa<\\xcct\\xa2<oK\\x89\\xbc79\\xaa\\xbc\\x88\\x050\\xbc\\x1a\\xfdq=\\x0eE\\xa7;T\\xd0\\x19\\xbc\\x92\\xc90\\xbcp\\xbce\\xbc3\\xdf\\xce;\\xf6\\x84\\xa5<;\\xee<\\xbc{\\xfdx\\xbcR\\x8cc<\\x18\\xe7\\xcc\\xbc\\x92L\\x9e;\\xa4t\\xe9\\xbc}\\xbe\\xc19i\\xd5\\xad;\\xff2\\x01\\xbcE\\xb8\\x98\\xbc\\x9e,\\x9f<\\xc8\\x14l\\xba\\xfb\\xd8\\xa5;\\xf7\\xfb\\xdc\\xbcv\\xb5\\xae9:\\xcc\\xe19\\xa3zD\\xba\\xca\\xd5\\xb4\\xbc\\x89\\'\\x8b\\xbc\\x8c\\xdc\\x9d\\xbb\\x87\\xddy\\xbc\\xbfl\\xeb\\xbc\\xa5\\x96\\xc4<HEu\\xbc\\xaa\\x0c\\xa0;X\\xfc\\xe3\\xbc\\x11\\x00\\x95\\xbcg\\x14\\xe5<\\x1e\\xd4_<\\xf3\\xcf\\x12;a\\xa4d\\xbcJ\\x06>\\xbb$D\\xe0\\xbb\\xb8]}<Z\\xc3\\x07<\\x13\\x99\\'<*7N<\\xbf\\x17\\x0f\\xba\\x1b%\\xa8<\\x84\\xabT\\xbc8-t\\xbc\\xc6\\x81\\xb4\\xbcN\\xb5\\xf5;R\\x8c\\xe3\\xbc\\xcd\\x90\\xa2;\\xa7/W\\xbck\\xeb\\xd2<\\xdc+\\x11\\xbd\\x84\\xab\\xd4\\xbc\\x94\\xe50\\xbd\\xe4\\xb7\\x11=m/\\x89<\"4\\x16\\xbd\\x9ck\\xd6\\xbc\\xaa\\xe4\\xe9<\\xf9\\x94o\\xbb\\x89\\xa4\\x9d\\xbc\\xadD\\xa0\\xbb_\\x11-\\xbe\\xc4\\xe8!<d_\\xd2\\xbb?B\\xbd;=\\xaf\\x85<\\x98\\xbc\\x9e<\\xf3R\\x80<\\x90\\x8bU;\\x99-\\xfb\\xbb\\xc0\\x0bY;\\x18d_;[\\xdf\\x87:Hm+\\xbc\\x00\\'\\xcb\\xbc\\xa4\\x9c\\x9f<Y\\x9bQ\\xbc\\x8dS\\xd5\\xbc\\xea|\\xee<6\\x9a<\\xbc\\x18j\\xba<t\\x9f\\x89<\\xab\\x89\\xb2\\xbbI\\x8f\\x06< \\x18\\x16\\xbd\\xfe\\n\\xcb;\\xc3\\xc6F<2\\xbd\\xf3\\xbc\\x8aC\\x8b<n\\xac\\x9b\\xbc\\xac\"\\xc5\\xbbj\\xf7\\x88\\xbc\\x02\\xe8\\x93<\\xf3\\xc97\\xbc?\\xbfO\\xbc\\x0b\\x13\\x82<\\x08\\xdb\\x81;e\\xfe\\xbf\\xbcW\\x02\\xbf<\\xbfr\\xc6<a\\xaa?=l\\x90\\x1b<\\xf6\\x01\\xb8<\\x81m\\xf9\\xbb\\xbb\\x95\\xfd;bI\\xad\\xbc\\x0fg\\x82;\\xad\\xc7\\r=\\xf6\\x07\\x13\\xbc\\xa7W\\x8d<[4\\xe4\\xbc\\xe7\\xe96<?\\xbf\\xcf\\xbc\\xcd\\xe5~<\\xa3z\\xc4;\\xa7W\\x8d\\xbcIg\\xd0;\\x7fWT<\\xa4\\x1f\\x8d;\\x00O\\x01\\xbc\\xb9\\xa7\\x0e\\xbc\\tR9\\xbc:\\xf4\\x17;\\xcd\\x13\\x90<b\\xcc\\x1a\\xbc\\xde\\xc4\\xa39\\x9f\\x9d\\xfb;\\x0b\\xe5\\xf0;\\x02=\\xf0<}G\\n\\xbc\\x8d\\xd6B<\\x11\\x00\\x95\\xbb\\xca\\xad~;p\\xc2\\xc0\\xbb\\x17\\xc5\\xf1;\\xd9p\\xa3<\\x81s\\xd4\\xbcz\\x86\\xc1\\xbcpg\\x89<00\\x17\\xbb\\x07\\xb9\\xa6;\\x11}\\xa7\\xbc\\xae\\xc12<|%/<u\\x93\\xd3\\xbbX\\xa7\\x07\\xbd\\xb8\\x8b\\x8e<\\x04\\xfe\\xb8;\\xe3\\x8f\\xdb<>\\xcb\\x05=k\\xf1-\\xbb\\xf0\\x1a\\x00<\\x08\\xad\\xf0\\xbc\\xd7\\xb55<\\xc5\\x87\\x0f<\\x96\\xf5z\\xbc\\xb3\\xb4\\xa0<\\x96\\xf5\\xfa;]\\xcdv\\xbc\\xe9\\x82\\xc9\\xbc\\xafZ\\xc5;\\xd4}\\xb5:L\\x9fP\\xbaK\">\\xbci\\xd5\\xad<\\xe6JI<\\x82\\x8fT<i\\xdb\\x08=\\x93\\xeb\\x8b<\\xa5\\x19\\xb2<\\x8a\\x1bU\\xbb\\xe4\\xb7\\x11\\xbc\\x07<\\x94<\\x8eo\\xd5<*=)<\\xc3CY\\xbc\\xe0\\xd4m;X\\xa7\\x07\\xbc\\xcf\\xa6G\\xbc~5y<\\xe7\\xe96\\xbb\\x9d\\x87V=\\x87\\xe3T\\xbc9OO<\\xc6\\x81\\xb4;\\xc4=\\xfe\\xba%l\\x16\\xbcNZ\\xbe\\xbd\\xdb\\x8c\\xa3\\xbb\\x93\\xeb\\x0b<\\xb9\\xfc\\xea<6\\x9a<\\xbc\\x8f\\xecg<\\xa2^D\\xbc\\n\\xf1\\xa6;\\x08\\xdb\\x01\\xbd\\x9b\\xcc\\xe8<<\\n=\\xbc.\\x14\\x17\\xbd:w\\x85\\xbc\\xcd\\xe5\\xfe;\\xa3\\x03\\r=W\\x02?\\xbc\\x04\\x04\\x94\\xbch\\xb3\\xd2\\xbb\\xe2s\\xdb9\\xca\\xdb\\x8f<\\x17\\xf3\\x02\\xbb\\x0e\\x1d\\xf1\\xbb\\xb2\\x98 \\xbc\\t\\xf7\\x81\\xbc\\xcaX\"\\xbd\\xaag\\xd7\\xbb\\x0f?\\xcc\\xbc\\xa9E\\xfc;\\xf5h\\xa5\\xb9\\x91*C<\\x0b\\x13\\x02<)\\x15s<I\\xe4\\xe2\\xbc\\xbex\\xa1<\\xe2s[:\\x01\\xcc\\x93<\\xa6;\\x8d\\xbc\\x85D\\xe7\\xbb\\xbb\\xc3\\x8e;1\\xcf\\x04\\xbd!\\x8fM<\\xbf\\xefX<\\xf3R\\x00\\xbc\\xb7i\\xb3;\\xc8\\xbf\\x0f=\\x91\\xad0\\xbcTM\\xac<\\x96\\xfb\\xd5<)\\x15s<q\\xde\\xc0\\xbct\\x9f\\t\\xbc\\xe4\\xb7\\x91\\xbc,{\\x84\\xbc\\xc7u\\xfe\\xb9:\\xcca;\\xed_\\x92;\\xce\\x84\\xec;\\x89\\x9eB<Hm+;\\xdb\\x8c\\xa3<\\r\\xa69\\xbc\".\\xbb<\\xc6\\xfeF\\xbdg\\x14e<\\xe0\\xd4\\xed;u\\x8d\\xf8\\xba]\\xfb\\x87\\xbc\\xa1d\\x9f\\xbc\\xaf\\xe3\\r\\xbb\\xd8\\xd15\\xbc\\x18d\\xdf\\xbc8-\\xf4\\xba+_\\x04\\xbc\\xef\\xf2I;\\xf1\\x8b\\xdc\\xbc\\xb37\\x8e\\xbcA\\xd5t;`\\xb0\\x9a;\\x14\\xbb\\x02=\\xc6\\x04\"<\\xed\\xb4\\xee\\xbb\\x99-\\xfb\\xbc\\xc9\\xb94;#\\xa5\\xf2\\xbc\\xef\\xf8$\\xbc\\x91\\xad\\xb0<\\xbd\\xd93<;et\\xbc%l\\x16<\\x83\\xb7\\n\\xbd\\xe3\\x12I<\\xd0\\x1d\\x7f\\xbbiX\\x9b<\\xa3\\x80\\x1f\\xbd\\x12\\xf4^;\\xd1\\xbc\\xec;\\x15\\xd7\\x02\\xbd\\xc9\\xb3Y\\xbcu\\x8dx<\\x1eW\\xcd\\xbcv,\\xe6\\xbb\\xe4\\xb1\\xb6\\xbb]\\xcdv\\xbd\\xf6\\x07\\x93<l\\x90\\x1b\\xbb?\\xbfO:\\xed\\xdc\\xa4\\xbc>\\xcb\\x85\\xbc!\\x8f\\xcd<\\xb37\\x0e:\\x993\\xd6\\xbc\\xb5%}:\\xa9m2\\xbdt\\x9f\\x89<F\\xac\\xe2\\xbc\\xa0\\xbf\\xd6\\xbc3h\\x97\\xbc\\xd7,m;\\x11\\x00\\x15<#P\\x96\\xba\\x98\\x94\\xe8\\xbb\\xf0\\x97\\x12:&\\xddr;|\\x9cf\\xbc\\x98\\xbc\\x9e\\xbb\\x87\\xe3\\xd4;\\xa6\\r\\xfc;\\xa9s\\r;\\x02\\xe8\\x13;\\xfe\\n\\xcb<\\xce\\x07\\xda;%\\xe9(<\\xa4\\xf7\\xd6<\"4\\x16\\xbdPv><\\xb9\\xfcj<9OO\\xbc\\x05 \\x94\\xbc\\x90\\x0eC<\\xd3\\x00\\xa3<\\xbc4\\xeb<\\x94h\\x9e\\xbckt\\x9b\\xbc\\x0e\\xc8\\x94\\xbc\\xaf\\xb5|<\\xae>\\xc5\\xbc4\\x01\\xaa\\xb9\\xff,&<\\x86\\xe9/<\\xe4.\\xc9<\\xb2\\x1b\\x0e<*\\xba\\xbb\\xbb\\xc2\\xaaF=)\\xc0\\x96<K(\\x99<\\\\\\xd9,\\xbc\\xd7,\\xed\\xbckt\\x9b\\xbb\\x96~C<;et<:w\\x85<O|\\x99\\xbcM\\xbbP=\\x8c\\xdc\\x9d\\xbc@<b;\\xdf;[\\xbbd\\xdc\\xe4:W\\x85,\\xbc\\n\\xf1&\\xbd\\xc5\\xdc\\xeb\\xbb\\x08\\xad\\xf0\\xbb\\x98?\\x0c\\xbd\\xa5\\x96\\xc4\\xbc!\\x95(\\xbc\\xdb\\x8c#\\xbc\\xc2\\xa4\\xeb;C\\x1f\\x86<\\xf3L%<\\xa3\\x03\\r\\xbd/\\x85\\xf3\\xbc^ld\\xbc\\x01CK<\\xd8\\xd7\\x10=Z\\xbd,<\\x1cG\\x03\\xbcw\\xd1\\xae<\\xb2\\x153=%f\\xbb\\xbb\\xdb\\x86H\\xbc\\xa65\\xb2;5\\xf5\\xf3\\xbb\\xf0\\x97\\x12;\\x9f\\xcb\\x8c\\xbc4\\x84\\x17<\\xe2\\x18$\\xbc%f\\xbb\\xbc\\xad\\x9fW<\\x1c\\xbe:<\\xc0\\x8eF<u\\x93\\xd3;3\\xe5)9GKP\\xbc_\\x0b\\xd2:\\xb7\\xe6E<\\x13\\x16\\xba\\xbc\\xe0\\xda\\xc8\\xbcfuw\\xbc\\xd0\\xc8\";wNA\\xbd<\\x8d*\\xbd\\xd4\\xf4\\xec;#P\\x16=\\xccn\\xc7;\\'\\xffM<\\x080^=V\\xe6\\xbe<t\\x16\\xc1;bC\\xd2;\\xf3R\\x80\\xbb\\xdeA\\xb6\\xbc\\xed_\\x92\\xbcn#\\xd3<\\x92\\xc9\\xb0\\xbc\\x11Uq<\\xe2\\x9b\\x91;\\xa7\\xaci\\xbc\\x1d5r<$D\\xe0;\\xc4=~\\xbb\\xcd\\xe5~;=\\xaf\\x05<\\xca\\xdb\\x8f<4\\x07\\x05<$D`;\\x13\\x16\\xba\\xbcW\\x8b\\x07\\xbdZ\\xbd\\xac;\\xcbRG\\xbdf\\xa3\\x08<\\nn9<.\\xec`<\\x02k\\x81=\\x13\\x16:<#\\xa5r\\xbcrU\\xf8;v\\xb5.<\\x11\\x83\\x82<\\xf3\\xcf\\x92\\xbc\\xf3R\\x00\\xbc\\x9f\\xcb\\x0c\\xba\\x99-\\xfb\\xbc)C\\x04=l\\x13\\t\\xbc\\xa8\\xce\\xc4\\xbbK\\xab\\x06\\xba\\'\\x82\\xbb\\xbc\\x19\\t(\\xbc\\xf9\\x94\\xef;=\\x04b<e\\xfe?\\xbc\\x1b\\x1f\\xcd\\xbc\\xc1\\xb0!=\\xf4n\\x80;\\xb37\\x8e<\\x90\\xb3\\x8b<)\\x15\\xf3\\xbb\\xf3R\\x80\\xbc\\xb8\\x02F\\xbc\\xc7u~\\xbci\\xad\\xf7\\xb9\\x05\\xa3\\x81\\xbd\\xca\\xad~\\xbc\\x99\\xb6C<\\xf4\\xeb\\x12<\\xf0\\x1a\\x80\\xbc\\x12\\xf4^;\\xb1\\xf92\\xbc\\x0e\\xc8\\x94;\\x03\\xdc\\xdd\\xbc\\x06\\x14\\xde\\xbcR7\\x87;\\xf16\\x80\\xbc\\x9d\\x10\\x9f;X$\\x9a\\xbb\\x1b%\\xa8\\xbc\\x19\\x8c\\x15\\xbd\\x02e\\xa6<(!)<\\xa5\\x13W<\\xdd\\x1f[\\xbc'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_hash_docs[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List, Dict, Optional\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "redis_url_params = {\n",
    "    \"redis_host\": redis_host,\n",
    "    \"redis_port\": redis_port,\n",
    "    \"redis_database\": redis_database,\n",
    "    \"redis_password\": redis_password,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redis_url(\n",
    "    redis_host: str,\n",
    "    redis_port: int,\n",
    "    redis_database: str,\n",
    "    redis_password: Union[str, None],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Create a redis uri from given args\n",
    "    redis://[username:user_pwd@]name_of_host [:port_number_of_redis_server] [/DB_Name]\n",
    "    redis://[[username]:[password]]@localhost:6379/0\n",
    "    \"\"\"\n",
    "    if not redis_password:\n",
    "        redis_url = f\"redis://{redis_host}:{redis_port}/{redis_database}\"\n",
    "        logger.debug(f\"Redis url is {redis_url}\")\n",
    "\n",
    "    else:\n",
    "        redis_url = f\"redis://default:{quote(redis_password)}@{redis_host}:{redis_port}/{redis_database}\"\n",
    "        logger.debug(f\"Redis url is {redis_url}\")\n",
    "\n",
    "    return redis_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedisVectorStoreRetriever(VectorStoreRetriever):\n",
    "    \"\"\"Retriever for Redis VectorStore.\"\"\"\n",
    "\n",
    "    vectorstore: Any\n",
    "    \"\"\"Redis VectorStore.\"\"\"\n",
    "    search_type: str = \"similarity\"\n",
    "    \"\"\"Type of search to perform. Can be either\n",
    "    'similarity',\n",
    "    'similarity_score_threshold',\n",
    "    \"\"\"\n",
    "\n",
    "    search_kwargs: Dict[str, Any] = {\n",
    "        \"num_results\": 5,\n",
    "        \"score_threshold\": 0.5,\n",
    "        \"extracted_ner_heads\": {},\n",
    "    }\n",
    "\n",
    "    allowed_search_types = [\n",
    "        \"similarity\",\n",
    "        \"similarity_score_threshold\",\n",
    "    ]\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    async def _aget_relevant_documents(\n",
    "        self,\n",
    "        query: str,\n",
    "    ) -> List[Dict]:\n",
    "        if self.search_type == \"similarity\":\n",
    "            # remove score_threshold from search_kwargs\n",
    "            self.search_kwargs.pop(\"score_threshold\", None)\n",
    "            docs = await self.vectorstore.retrieve_from_index(\n",
    "                query, **self.search_kwargs\n",
    "            )\n",
    "\n",
    "        elif self.search_type == \"similarity_score_threshold\":\n",
    "            docs = await self.vectorstore.retrieve_from_index_score_threshold(\n",
    "                query, **self.search_kwargs\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"search_type of {self.search_type} not allowed.\")\n",
    "        return docs\n",
    "\n",
    "    def _get_relevant_documents(\n",
    "        self,\n",
    "        query: str,\n",
    "    ) -> List[Dict]:\n",
    "        return asyncio.run(self._aget_relevant_documents(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedisvlVectorDB:\n",
    "    def __init__(\n",
    "        self,\n",
    "        static_metadata: list,\n",
    "        added_metadata: list,\n",
    "        embedding_field_name: str,\n",
    "        vector_field_name: str,\n",
    "        embedding_dimension: int,\n",
    "        distance_metric: str,\n",
    "        vector_algo: str,\n",
    "        index_name: str,\n",
    "        doc_embedder: DocumentEmbedder,\n",
    "        llm_re_ranking: bool,\n",
    "        redis_connection: Optional[Redis] = None,\n",
    "        redis_url_params: Optional[Dict[str, Union[str, int]]] = None,\n",
    "    ):\n",
    "        self.static_metadata = static_metadata\n",
    "        self.added_metadata = added_metadata\n",
    "        self.embedding_field_name = embedding_field_name\n",
    "        self.vector_field_name = vector_field_name\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.distance_metric = distance_metric\n",
    "        self.vector_algo = vector_algo\n",
    "        self.index_name = index_name\n",
    "        self.doc_embedder = doc_embedder\n",
    "        self.llm_re_ranking = llm_re_ranking\n",
    "        self.cross_encoder_reranker = None\n",
    "\n",
    "        if self.llm_re_ranking:\n",
    "            self._initialize_reranker()\n",
    "\n",
    "        if redis_connection:\n",
    "            self.redis_connection = redis_connection\n",
    "        else:\n",
    "            self.redis_connection = None\n",
    "            self.redis_url = (\n",
    "                get_redis_url(**redis_url_params) if redis_url_params else None\n",
    "            )\n",
    "\n",
    "    def _initialize_reranker(self):\n",
    "        logger.info(\"Using the cross-encoder reranker for re-ranking.\")\n",
    "        self.cross_encoder_reranker = HFCrossEncoderReranker(\n",
    "            \"cross-encoder/ms-marco-MiniLM-L-6-v2\", limit=5\n",
    "        )\n",
    "\n",
    "    def _create_schema(\n",
    "        self,\n",
    "    ):\n",
    "        \"\"\"Schema creation for vector DB index\"\"\"\n",
    "        fields = (\n",
    "            [\n",
    "                {\"name\": name, \"type\": \"text\"}\n",
    "                for name in self.static_metadata + [self.embedding_field_name]\n",
    "            ]\n",
    "            + [{\"name\": name, \"type\": \"tag\"} for name in self.added_metadata]\n",
    "            + [\n",
    "                {\n",
    "                    \"name\": self.vector_field_name,\n",
    "                    \"type\": \"vector\",\n",
    "                    \"attrs\": {\n",
    "                        \"dims\": self.embedding_dimension,\n",
    "                        \"distance_metric\": self.distance_metric,\n",
    "                        \"algorithm\": self.vector_algo,\n",
    "                        \"datatype\": \"float32\",\n",
    "                    },\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        schema = {\n",
    "            \"index\": {\n",
    "                \"name\": f\"{self.index_name}\",\n",
    "                \"prefix\": \"redis_doc\",\n",
    "            },\n",
    "            \"fields\": fields,\n",
    "        }\n",
    "\n",
    "        return schema\n",
    "\n",
    "    async def get_redis_index(\n",
    "        self,\n",
    "    ):\n",
    "        \"\"\"Get async-redis index connection.\"\"\"\n",
    "        schema = self._create_schema()\n",
    "        if self.redis_connection is not None:\n",
    "            index = AsyncSearchIndex.from_dict(schema)\n",
    "            index = await index.set_client(self.redis_connection)\n",
    "            return index\n",
    "        else:\n",
    "            client = Redis.from_url(self.redis_url)\n",
    "            index = AsyncSearchIndex.from_dict(schema)\n",
    "            index = await index.set_client(client)\n",
    "            return index\n",
    "\n",
    "    async def _delete_index(self, index: AsyncSearchIndex):\n",
    "        try:\n",
    "            await index.delete()\n",
    "        except Exception as e:\n",
    "            logger.info(\"No index present to drop\")\n",
    "\n",
    "    async def drop_index(self):\n",
    "        \"\"\"Drop the index.\"\"\"\n",
    "\n",
    "        index = await self.get_redis_index()\n",
    "        if await index.exists():\n",
    "            await self._delete_index(index)\n",
    "            logger.info(f\"Deleted the index\")\n",
    "            return None\n",
    "\n",
    "    async def _load_docs(self, index: AsyncSearchIndex, embedding_hashes: list):\n",
    "        \"\"\"Load list of dicts to the index.\"\"\"\n",
    "        keys = await index.load(embedding_hashes)\n",
    "        return keys\n",
    "\n",
    "    async def create_redis_index_upload(\n",
    "        self, embedding_hashes: list, drop_index: bool = True\n",
    "    ):\n",
    "        \"\"\"Create a new redis index and upload the documents from the embedding hashes\"\"\"\n",
    "        index = await self.get_redis_index()\n",
    "        if drop_index:\n",
    "            await self._delete_index(index)\n",
    "\n",
    "        await index.create(overwrite=True)\n",
    "\n",
    "        keys = await self._load_docs(index, embedding_hashes)\n",
    "        logger.info(f\"created redis index and uploaded {len(keys)} records\")\n",
    "        return keys\n",
    "\n",
    "    async def update_redis_index(self, embedding_hashes: list):\n",
    "        \"\"\"Update the redis index with the new documents.\"\"\"\n",
    "        index = await self.get_redis_index()\n",
    "        if await index.exists():\n",
    "            updated_keys = await self._load_docs(index, embedding_hashes)\n",
    "            logger.info(\n",
    "                f\"Appended to redis index and uploaded {len(updated_keys)} records\"\n",
    "            )\n",
    "            return updated_keys\n",
    "        else:\n",
    "            logger.error(\"No index present to update\")\n",
    "            return None\n",
    "\n",
    "    async def _curate_query(\n",
    "        self,\n",
    "        query: str,\n",
    "        num_results: int,\n",
    "    ):\n",
    "        \"\"\"Curate the query for the search.\"\"\"\n",
    "\n",
    "        query_vector = await self.doc_embedder.content_embedder(query, \"vectors\")\n",
    "        query_search = VectorQuery(\n",
    "            vector=query_vector,\n",
    "            vector_field_name=self.vector_field_name,\n",
    "            return_fields=self.static_metadata\n",
    "            + [\"vector_distance\", self.embedding_field_name]\n",
    "            + self.added_metadata,\n",
    "            num_results=num_results,\n",
    "            return_score=True,\n",
    "        )\n",
    "        return query_search\n",
    "\n",
    "    async def _conditional_filters(self, extracted_ner_heads: dict):\n",
    "        \"\"\"Apply conditional filters on the extracted NER heads.\"\"\"\n",
    "\n",
    "        condition_ls = [\n",
    "            Tag(k.lower()) == v.lower() for k, v in extracted_ner_heads.items()\n",
    "        ]\n",
    "        full_condition = None\n",
    "        for i in range(len(condition_ls)):\n",
    "            if i == 0:\n",
    "                full_condition = condition_ls[i]\n",
    "            else:\n",
    "                full_condition = full_condition & condition_ls[i]\n",
    "\n",
    "        return full_condition\n",
    "\n",
    "    async def _search_index_results(\n",
    "        self,\n",
    "        index: AsyncSearchIndex,\n",
    "        query: str,\n",
    "        num_results: int,\n",
    "        extracted_ner_heads: dict,\n",
    "    ):\n",
    "        \"\"\"Search the index for the query and return the results.\"\"\"\n",
    "\n",
    "        query_search = await self._curate_query(\n",
    "            query=query,\n",
    "            num_results=num_results,\n",
    "        )\n",
    "        if extracted_ner_heads:\n",
    "            logger.info(\n",
    "                \"Extracted NER heads present in the query and applying conditional filters.\"\n",
    "            )\n",
    "            if len(extracted_ner_heads) > 0:\n",
    "                full_condition = await self._conditional_filters(\n",
    "                    extracted_ner_heads=extracted_ner_heads\n",
    "                )\n",
    "                query_search.set_filter(full_condition)\n",
    "\n",
    "        # search the index for the query and return the results\n",
    "        results = await index.query(query_search)\n",
    "        return results\n",
    "\n",
    "    async def _rerank_results(\n",
    "        self,\n",
    "        results: list,\n",
    "        query: str,\n",
    "    ):\n",
    "        \"\"\"Rerank the results using the cross-encoder.\"\"\"\n",
    "\n",
    "        re_rank_raw_docs = [r[\"page_content\"] for r in results]\n",
    "        ids = [{\"id\": r[\"id\"]} for r in results]\n",
    "        re_rank_op = await self.cross_encoder_reranker.arank(query, re_rank_raw_docs)\n",
    "        op_ls = [\n",
    "            {\"content\": op[0][\"content\"], \"score\": op[1]}\n",
    "            for op in zip(re_rank_op[0], re_rank_op[1])\n",
    "        ]\n",
    "        filter_op_ls = list(filter(lambda x: x[\"score\"] > 0, op_ls))\n",
    "        filter_op_ls = list(zip(ids, filter_op_ls))\n",
    "        return filter_op_ls\n",
    "\n",
    "    async def _re_rank_selection(self, reranked_results, results):\n",
    "        \"\"\"Select the ids from the reranked results and filter the results based on the final list.\"\"\"\n",
    "\n",
    "        # selecting ids from the reranked results\n",
    "        final_results_ids = [r[0][\"id\"] for r in reranked_results]\n",
    "        # filter the results based on the final list that we got from reranking results\n",
    "        final_results = [r for r in results if r[\"id\"] in final_results_ids]\n",
    "        return final_results\n",
    "\n",
    "    async def retrieve_from_index(\n",
    "        self,\n",
    "        query: str,\n",
    "        num_results: int,\n",
    "        extracted_ner_heads: dict,\n",
    "    ):\n",
    "        \"\"\"Retrieve the results from the index.\"\"\"\n",
    "\n",
    "        # get the index connection from redis\n",
    "        index = await self.get_redis_index()\n",
    "        # search the index for the query and return the results\n",
    "        redis_results = await self._search_index_results(\n",
    "            index,\n",
    "            query,\n",
    "            num_results,\n",
    "            extracted_ner_heads,\n",
    "        )\n",
    "        if self.llm_re_ranking:\n",
    "            logger.info(\"Reranking the results using the cross-encoder.\")\n",
    "            reranked_results = await self._rerank_results(redis_results, query)\n",
    "\n",
    "            # select the ids from the reranked results and filter the results based on the final list\n",
    "            final_selected_results = await self._re_rank_selection(\n",
    "                reranked_results, redis_results\n",
    "            )\n",
    "            return final_selected_results\n",
    "\n",
    "        return redis_results\n",
    "\n",
    "    async def retrieve_from_index_score_threshold(\n",
    "        self,\n",
    "        query: str,\n",
    "        num_results: int,\n",
    "        extracted_ner_heads: dict,\n",
    "        score_threshold: float,\n",
    "    ):\n",
    "        \"\"\"Retrieve the results from the index based on the score threshold.\"\"\"\n",
    "\n",
    "        retrieved_results = await self.retrieve_from_index(\n",
    "            query,\n",
    "            num_results,\n",
    "            extracted_ner_heads,\n",
    "        )\n",
    "        filtered_results = [\n",
    "            r\n",
    "            for r in retrieved_results\n",
    "            if (1 - float(r[\"vector_distance\"])) > score_threshold\n",
    "        ]\n",
    "\n",
    "        return filtered_results\n",
    "\n",
    "    def as_retriever(self, **kwargs: Any) -> RedisVectorStoreRetriever:\n",
    "        return RedisVectorStoreRetriever(vectorstore=self, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/langchain_unstructured/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "redis_vector_db = RedisvlVectorDB(\n",
    "    static_metadata,\n",
    "    added_metadata,\n",
    "    embedding_field_name,\n",
    "    vector_field_name,\n",
    "    embedding_dimension,\n",
    "    distance_metric,\n",
    "    vector_algo,\n",
    "    index_name,\n",
    "    doc_embedder,\n",
    "    llm_re_ranking,\n",
    "    redis_connection=None,\n",
    "    redis_url_params=redis_url_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "# Create the index and upload the documents\n",
    "new_keys = await redis_vector_db.create_redis_index_upload(embedded_hash_docs, drop_index=True)\n",
    "print(len(new_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "# Update new documents on the same index\n",
    "# update_keys = await redis_vector_db.update_redis_index(embedded_hash_docs)\n",
    "# print(len(update_keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retriver from the Redis Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# await redis_vector_db.drop_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Which parties are involved in the MSA contracts?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_op = await redis_vector_db.retrieve_from_index(query, 5, {\"contractor_name\": \"Accenture\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_op2 = await redis_vector_db.retrieve_from_index_score_threshold(query, 5, {\"contractor_name\": \"Accenture\"}, 0.8)\n",
    "# result_op2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = redis_vector_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"num_results\": 5,\n",
    "        \"score_threshold\": 0.7,\n",
    "        \"extracted_ner_heads\": {\"contractor_name\": \"Accenture\"},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'redis_doc:f77b4c35d0fe4f2d9b627df24e19f247',\n",
       "  'vector_distance': '0.17741048336',\n",
       "  'source': 'accenture__original__msa completely signed accenture',\n",
       "  'page_number': '2',\n",
       "  'file_name': 'msa completely signed accenture',\n",
       "  'token_size': '564',\n",
       "  'timestamp': '2024-08-15 15:07:21.922368',\n",
       "  'page_content': 'THIS AGREEMENT (or \"MSA\") is made on [date]\\n\\nBETWEEN:\\n\\n(1) ANHEUSER-BUSCH INBEV PROCUREMENT GMBH of Suurstoffi 22, 6343 Rotkreuz, Switzerland (\"AB InBev Procurement\"); and\\n\\n(2) AMBEV LUXEMBOURG SARL SENNINGERBERG, RISCH BRANCH, a Swiss branch of a Luxembourg company which has its registered office at Suurstoffi 22, Rotkreuz, 6343, Switzerland (\"AmBev Luxembourg\"),\\n\\n(collectively the \"Lead Customer\"); and\\n\\n(3) ACCENTURE AG, which has its registered address at Fraumuensterstrasse 16, 8001 Zurich, Switzerland (the \"Lead Supplier\").\\n\\nTHE PARTIES AGREE as follows:\\n\\n1 OBJECTIVES AND PRINCIPLES\\n\\n1.1 Objectives - The objective of this Agreement is to create a contracting framework for the Services performed for the ABI Group by the Supplier Group.\\n\\n1.2 Principles\\n\\n(a) The MSA provides a set of guidelines against which the members of the Supplier Group should seek to make their future offers to perform Services.\\n\\n(b) This Agreement is a master agreement negotiated between the parties on behalf of their respective groups, which is intended to have equivalent master services agreements entered into between the Lead Customer and other suppliers (whereby the Lead Customer may contract on behalf of the ABI Group for the provision of similar services from other suppliers), will assist the Lead Customer and Customers in comparing proposals from different suppliers in response to RFPs issued by the ABI Group for Services, and should speed up the SOW contracting process.\\n\\n(c) The MSA and its equivalent master services agreements entered into with other suppliers should enable the Lead Customer to track the level of compliance of a supplier and its Affiliates to the ABI Group\\'s preferred contracting framework across the world.\\n\\n(d) However, each member of the ABI Group may decide what is better for a particular deal and can, subject to clause 3.2, agree with the Supplier, in an SOW, to overwrite specifics of the MSA.\\n\\n1.3 MSA & SOW\\n\\n(a) The Lead Parties\\' intention is to incorporate and standardise as much of the commercial and legal terms between the ABI Group and the Supplier Group applying to the provision of Services as is reasonable.\\n\\n(b) While specific terms may, subject to clause 3.2, be overridden by the individual SOWs it is the Lead Parties\\' intention that this is the exception rather than the rule, especially with the legal terms.\\n\\n(c) Each SOW will be a standalone contract, entered into between a member of the ABI Group and a member of the Supplier Group within the framework created by this MSA,',\n",
       "  'contractor_name': 'accenture',\n",
       "  'file_version': 'original'},\n",
       " {'id': 'redis_doc:50f4fc7ad750477abd77a7969314f5d2',\n",
       "  'vector_distance': '0.202511787415',\n",
       "  'source': 'accenture__original__msa completely signed accenture',\n",
       "  'page_number': '90',\n",
       "  'file_name': 'msa completely signed accenture',\n",
       "  'token_size': '388',\n",
       "  'timestamp': '2024-08-15 15:12:56.760965',\n",
       "  'page_content': '```\\nDocuSign Envelope ID: 31EF68C8-71A9-4F6A-95F4-4239336148A6\\n\\n(b) Scope\\n\\nThe Contract Management Level will meet quarterly to manage the business partnership and review MSA usage. The Carry Management Level will carry out the following activities:\\n\\n(i) review the list of newly signed SOWs under the MSA and their level of compliance with the principles of the MSA;\\n(ii) review the list of SOWs coming to the end of their SOW Terms during the period;\\n(iii) review the revenue evolution;\\n(iv) review of issues arising under existing SOWs;\\n(v) identify opportunities for amendment to the MSA to be presented to the Executive Level;\\n(vi) presentation of findings of reviews, benchmarking studies, and audits to the Executive Level; and\\n(vii) Any other matters which require Contract Management Level activity.\\n\\n(c) Membership\\n\\nThe Program Management Level comprises managers appointed by the Lead Customer and the Lead Supplier as follows:\\n\\nLead Customer Representation          Lead Supplier Representation\\nCustomer Global Contract Manager      Supplier Account Manager\\nCustomer Global Procurement Manager   Service Contract Executive\\n\\n(d) Reporting\\n\\nThe Lead Supplier will provide the following reports:\\n\\n(i) revenue per month of all active SOWs during the period, with split by ABI Group zone;\\n(ii) list of newly signed SOWs during the period, with split by ABI Group zone;\\n(iii) for each newly signed SOW during the period, the Lead Supplier will list the gaps versus the principles of the MSA, with split by ABI Group zone;\\n(iv) list of all SOWs coming to the end of their SOW Terms during the period, with split by ABI Group zone; and\\n(v) value of Service Credits (arising; and becoming irrecoverable) during the period, with split by ABI Group zone.\\n\\n91\\n```',\n",
       "  'contractor_name': 'accenture',\n",
       "  'file_version': 'original'}]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# await retriever._aget_relevant_documents(query) # This is the async method to get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever._get_relevant_documents(query) # This is the sync method to get the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Langchain Summarizer chain with custom retriever and lecl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import (\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "    You are an AI assistant specialized in answering questions based on the provided documents. Your task is to answer the questions based on the documents provided.\n",
    "    The related documents are provided under the '<<<Documents>>>' context and the question is provided under the '<<<Question>>>' context.\n",
    "    You can use the documents to answer the questions.\n",
    "    The final answer should be a clear and concise answer to the question with the relevant information extracted from the documents provided under the '<<<Documents>>>' context.\n",
    "    The final answer should also be grammatically correct and should be in complete sentences and should be relevant to the question asked.\n",
    "    At the end of the answer, please provide a short and concise summary of the answer.\n",
    "    \"\"\"\n",
    "\n",
    "human_message = \"\"\"\n",
    "    <<<Documents>>>:\\n\n",
    "    {context}\n",
    "    <<<Question>>>:\\n\n",
    "    {question}\n",
    "\n",
    "    Answer: \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_generator(\n",
    "    system_message: str = \"\", human_message: str = \"\"\n",
    ") -> ChatPromptTemplate:\n",
    "    prompt_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessagePromptTemplate.from_template(system_message),\n",
    "            HumanMessagePromptTemplate.from_template(human_message),\n",
    "        ]\n",
    "    )\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "qna_prompt = prompt_generator(system_message, human_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    \"\"\" Format the documents for the prompt.\"\"\"\n",
    "    return \"\\n\\n\".join(doc[\"page_content\"] for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = get_gpt_model(\n",
    "    azure_deployment=os.getenv(\"CHAT_ENGINE_GPT4_DEPLOYMENT_NAME\"),\n",
    "    model_name=os.getenv(\"CHAT_ENGINE_GPT4_MODEL_NAME\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    openai_api_type=os.getenv(\"OPENAI_API_TYPE\"),\n",
    "    api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    temperature=0.0,\n",
    "    request_timeout=45,\n",
    "    max_retries=5,\n",
    "    seed=1234,\n",
    "    top_p=0.0001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | qna_prompt\n",
    "    | llm_model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = await rag_chain.ainvoke(\"Which parties are involved in the MSA contracts?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parties involved in the MSA contracts are:\n",
      "\n",
      "1. **ANHEUSER-BUSCH INBEV PROCUREMENT GMBH** of Suurstoffi 22, 6343 Rotkreuz, Switzerland (\"AB InBev Procurement\").\n",
      "2. **AMBEV LUXEMBOURG SARL SENNINGERBERG, RISCH BRANCH**, a Swiss branch of a Luxembourg company with its registered office at Suurstoffi 22, Rotkreuz, 6343, Switzerland (\"AmBev Luxembourg\").\n",
      "3. **ACCENTURE AG**, which has its registered address at Fraumuensterstrasse 16, 8001 Zurich, Switzerland (\"Lead Supplier\").\n",
      "\n",
      "These parties collectively form the \"Lead Customer\" and the \"Lead Supplier\" in the MSA contracts.\n",
      "\n",
      "**Summary:** The MSA contracts involve ANHEUSER-BUSCH INBEV PROCUREMENT GMBH, AMBEV LUXEMBOURG SARL SENNINGERBERG, RISCH BRANCH, and ACCENTURE AG.\n"
     ]
    }
   ],
   "source": [
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_unstructured",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
